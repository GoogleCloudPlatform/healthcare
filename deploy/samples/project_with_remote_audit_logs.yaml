# Copyright 2018 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Sample template to create three projects: a project for hosting audit-logs
# and two projects for hosting data. The data hosting projects have GCS buckets,
# BigQuery datasets, logging to GCS and BigQuery, and logs-based metrics for
# unexpected access.
#
# Usage:
# 1) Replace all fields with relevant values in (a copy of) this file.
# 2) Run gcloud init
# 3) run ./create_project.py --project_yaml=${NEW_PROJECT_YAML?}
# 4) When prompted, follow the steps to set up a Stackdriver account.

overall:
  organization_id: '12345678'           # Replace this with your Organization ID, or remove to setup without an organization.
  folder_id: '98765321'                 # Optional. Replace this with an existing folder within the organization.
  billing_account: 000000-000000-000000 # Replace this with your Billing Account.
  domain: domain.com                    # Replace this with your domain.

# Configure the audit logs hosting project here.
audit_logs_project:
  project_id: my-audit-logs             # Replace this with a unique ID for your audit logs project.
  owners_group: my-audit-logs-owners@mydomain.com   # Replace this with the owners group for this project.
  auditors_group: some-auditors-group@mydomain.com  # Replace this with your auditors group.
  create_deletion_lien: true
  audit_logs:  # Audit logs for acccess to the audit logs project itself.
    logs_bq_dataset:
      properties:
        # Naming convention: PROJECT_ID, with underscores instead of dashes.
        name: my_audit_logs
        location: US                    # Replace this with the desired the location for the BigQuery dataset holding audit logs for this project.
  stackdriver_alert_email: some-alerts-group@mydomain.com  # (OPTIONAL) Set a destination email for Stackdriver alerts.

forseti:
  project:
    project_id: my-forseti-project      # Replace this with a unique ID for your forseti project.
    owners_group: my-forseti-project-owners@mydomain.com    # Replace this with the owners group for this project.
    auditors_group: my-forseti-project-auditors@mydomain.com  # Replace this with your auditors group.
    create_deletion_lien: true
    terraform:
      state_storage_bucket:
        name: my-forseti-project-state
        location: US
    audit_logs:
      logs_bq_dataset:
        properties:
          name: my_forseti_project
          location: US
    stackdriver_alert_email: some-alerts-group@mydomain.com  # (OPTIONAL) Set a destination email for Stackdriver alerts.
  properties: # (OPTIONAL) Any non-default properties to set on the Forseti Terraform module.
    storage_bucket_location: us-east1

# Multiple dataset projects can be deployed at once with the one YAML file.
projects:
- project_id: my-project
  owners_group: my-project-owners@my-domain.com      # Replace this with the owners group for this project.
  auditors_group: some-auditors-group@my-domain.com
  data_readwrite_groups:
  - some-readwrite-group@my-domain.com
  data_readonly_groups:
  - some-readonly-group@my-domain.com
  - another-readonly-group@googlegroups.com
  create_deletion_lien: true
  # If alert email is present, create StackDriver alerts.
  stackdriver_alert_email: some-alerts-group@my-domain.com
  # These audit logs will be saved to the audit_logs_project.
  audit_logs:
    logs_gcs_bucket:
      properties:
        # For naming recommendations, see https://cloud.google.com/storage/docs/best-practices.
        name: logs-hash-of-my-project
        location: US
        storageClass: MULTI_REGIONAL
      ttl_days: 365
    logs_bq_dataset:
      properties:
        # Naming convention: PROJECT_ID, with underscores instead of dashes.
        name: my_project
        location: US
  resources:
    bq_datasets:
    - properties:
        name: us_data
        location: US
    - properties:
        name: euro_data
        location: EU
    gcs_buckets:
    - properties:
        location: US-CENTRAL1
        name: foo-data
        storageClass: REGIONAL
    pubsubs:
    - properties:
        topic: foo-topic
        accessControl:
        - role: roles/pubsub.publisher
          members:
          - group:foo-publisher@my-domain.com
        subscriptions:
        - name: foo-subscription
- project_id: my-other-project
  owners_group: my-other-project-owners@my-domain.com
  auditors_group: some-auditors-group@my-domain.com
  create_deletion_lien: true
  data_readwrite_groups:
  - some-readwrite-group@my-domain.com
  data_readonly_groups:
  - some-readonly-group@my-domain.com
  - another-readonly-group@googlegroups.com
  stackdriver_alert_email: some-alerts-group@my-domain.com
  audit_logs:
    logs_gcs_bucket:
      properties:
        # For naming recommendations, see https://cloud.google.com/storage/docs/best-practices.
        name: logs-hash-of-my-other-project
        location: US
        storageClass: MULTI_REGIONAL
      ttl_days: 365
    logs_bq_dataset:
      properties:
        name: my_other_project
        location: US
  resources:
    bq_datasets:
    - properties:
        name: us_data
        location: US
    gcs_buckets:
    - properties:
        location: EUROPE-WEST1
        name: foo-other-data
        storageClass: REGIONAL
