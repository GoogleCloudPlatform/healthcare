{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIMIC-III Datathon Tutorial",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "/piper/depot/google3/third_party/cloud/healthcare/datathon/nusdatathon18/bigquery_colab.ipynb?workspaceId=lastomato%3Alastomato0-lastomato-cloud-add_bq_colab-git5%3A%3Acitc",
          "timestamp": 1527177533891
        },
        {
          "file_id": "1feOtwLH7t-lHuKvDlQ0iR61rDMVvf7Wj",
          "timestamp": 1527116244197
        },
        {
          "file_id": "16EHw62feMPU-FI-HOhtS1y3zQjRmXrPV",
          "timestamp": 1527113933826
        }
      ],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "6fr_A5J1tVFQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Copyright 2018 Google Inc.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at\n",
        "\n",
        "> https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
      ]
    },
    {
      "metadata": {
        "id": "QT2sukPDtrWQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Datathon Tutorial\n",
        "\n",
        "The aim of this tutorial is to get you familiarized with BigQuery to query/filter/aggregate/export data with Python.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "You should already have had a valid Gmail account registered with the datathon organizers.\n",
        "  * If you do not have a Gmail account, you can create one at http://www.gmail.com. You need to notify datathon organizers to register your new account for data access.\n",
        "  * If you have not yet signed the data use agreement (DUA) sent by the organizers, please do so immediately to get access to the MIMIC-III dataset."
      ]
    },
    {
      "metadata": {
        "id": "xks2nlrtt-um",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "To be able to run the queries in this tutorial, you need to create a copy of this Colab notebook by clicking \"File\" > \"Save a copy in Drive...\" menu.\n",
        "You can share your copy with your teammates by clicking on the \"SHARE\" button on the top-right corner of your Colab notebook copy. Everyone with \"Edit\" permission is able to modify the notebook at the same time, so it is a great way for team collaboration. Before running any cell in this colab, please make sure there is a green check mark before \"CONNECTED\" on top right corner, if not, please click \"CONNECTED\" button to connect to a random backend.\n",
        "\n",
        "Now that you have done the initial setup, let us start playing with the data. First, you need to run some initialization code. You can run the following cell by clicking on the triangle button when you hover over the [ ] space on the top-left corner of the code cell below."
      ]
    },
    {
      "metadata": {
        "id": "rS9g4-r7uohe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.path as path\n",
        "import tensorflow as tf\n",
        "\n",
        "# Below imports are used to print out pretty pandas dataframes\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# Imports for accessing Datathon data using Google BigQuery.\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rlP2b-PKvUMk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Before running any queries using BigQuery, you need to first authenticate yourself by running the following cell. If you are running it for the first time, it will ask you to follow a link to log in using your Gmail account, and accept the data access requests to your profile. Once this is done, it will generate a string of verification code, which you should paste back to the cell below and press enter."
      ]
    },
    {
      "metadata": {
        "id": "HDL3CjUKvddl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0qezUBvxH7_6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The data-hosting project `physionet-data` has read-only access, as a result, you need to set a default project that you have BigQuery access to. A shared project `nus-datathon-2018-team-00` has already been created, and we will be using it throughout this tutorial.\n",
        "\n",
        "Note that during the datathon, all participants will be divided into teams and a Google Cloud project will be created for each team specifically. That project would be the preferred project to use. For now we'll stick with the shared project for the purpose of the tutorial.\n",
        "\n",
        "After datathon is finished, the shared project may either lock down access or be deleted, it's still possible to run queries from a project you own personally as long as you have access to the dataset hosting project."
      ]
    },
    {
      "metadata": {
        "id": "nx4ZDlJ6we9j",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "project_id='nus-datathon-2018-team-00'\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"]=project_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZondovXiw-zq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's define a few methods to wrap BigQuery operations, so that we don't have to write the configurations again and again."
      ]
    },
    {
      "metadata": {
        "id": "DIbbCE3YxLdM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Read data from BigQuery into pandas dataframes.\n",
        "def run_query(query):\n",
        "  return pd.io.gbq.read_gbq(query, project_id=project_id, verbose=False, configuration={'query':{'useLegacySql': False}})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VDfGS-0VxjpC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "OK, that's it for setup, now let's get our hands on the MIMIC demo data!"
      ]
    },
    {
      "metadata": {
        "id": "7wh4aG6fRubd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analysis\n",
        "\n",
        "Let's now run some queries adapted from the [MIMIC cohort selection tutorial](https://github.com/MIT-LCP/mimic-code/blob/master/tutorials/cohort-selection.ipynb).\n",
        "\n",
        "First let's run the following query to produce data to generate a histrogram graph to show the distribution of patient ages in ten-year buckets (i.e. [0, 10), [10, 20), ..., [90, âˆž)."
      ]
    },
    {
      "metadata": {
        "id": "0BKEaZ0mAS_a",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "df = run_query('''\n",
        "WITH ps AS (\n",
        "  SELECT\n",
        "    icu.subject_id,\n",
        "    icu.hadm_id,\n",
        "    icu.icustay_id,\n",
        "    pat.dob,\n",
        "    DATETIME_DIFF(icu.outtime, icu.intime, DAY) AS icu_length_of_stay,\n",
        "    DATE_DIFF(DATE(icu.intime), DATE(pat.dob), YEAR) AS age\n",
        "  FROM `physionet-data.mimic_demo.icustays` AS icu\n",
        "  INNER JOIN `physionet-data.mimic_demo.patients` AS pat\n",
        "    ON icu.subject_id = pat.subject_id),\n",
        "bu AS (\n",
        "  SELECT\n",
        "    CAST(FLOOR(age / 10) AS INT64) AS bucket\n",
        "  FROM ps)\n",
        "SELECT\n",
        "  COUNT(bucket) AS num_icu_stays,\n",
        "  IF(bucket >= 9, \">= 90\", FORMAT(\"%d - %d\", bucket * 10, (bucket + 1) * 10)) AS age_bucket\n",
        "FROM bu\n",
        "GROUP BY bucket\n",
        "ORDER BY bucket ASC\n",
        "''')\n",
        "\n",
        "df.set_index('age_bucket').plot(title='stay - age',kind='bar',legend=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v1IquJ4LTQzi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The query consists of 3 parts:\n",
        "\n",
        "1.   First we join `icustays` and `patients` tables to produce length of ICU stays in days for each patient, which is saved in a temporary table `ps`;\n",
        "2.   Next we put patients into buckets based on their ages at the time they got admitted into ICU in `bu` table;\n",
        "3.   The result data is filtered to include only the information required, i.e. `age_bucket` and `num_icu_stays`, to plot the chart."
      ]
    },
    {
      "metadata": {
        "id": "QenZBv-rxYEm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Note**: If you are having a hard time following the queries in this colab, or you want to know more about the table structures of MIMIC-III dataset, please consult [our colab for a previous Datathon held in Sydney](../../anzics18/tutorial.ipynb)."
      ]
    },
    {
      "metadata": {
        "id": "3TVRWd6JAYHS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's see if there is correlation between age and average length of stay in hours. Since we are using the age of patients when they get admitted, so we don't need to worry about multiple admissions of patients. Note that we treat the redacted ages (> 90) as noises and filter them out."
      ]
    },
    {
      "metadata": {
        "id": "Me7i5Z5pAZ4s",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "df = run_query('''\n",
        "WITH re AS (\n",
        "SELECT\n",
        "  DATETIME_DIFF(icu.outtime, icu.intime, HOUR) AS icu_length_of_stay,\n",
        "  DATE_DIFF(DATE(icu.intime), DATE(pat.dob), YEAR) AS age\n",
        "FROM `physionet-data.mimic_demo.icustays` AS icu\n",
        "INNER JOIN `physionet-data.mimic_demo.patients` AS pat\n",
        "  ON icu.subject_id = pat.subject_id)\n",
        "SELECT\n",
        "  icu_length_of_stay AS stay,\n",
        "  age\n",
        "FROM re\n",
        "WHERE age < 100\n",
        "''')\n",
        "\n",
        "df.plot(kind='scatter',x='age',y='stay')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W3l1HyDeBVvW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's take a look at another query which uses a filter that we often use, which is the current service that ICU patients are undergoing."
      ]
    },
    {
      "metadata": {
        "id": "iIw3ykjHOY-Y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "df = run_query('''\n",
        "WITH co AS (\n",
        "  SELECT\n",
        "    icu.subject_id,\n",
        "    icu.hadm_id,\n",
        "    icu.icustay_id,\n",
        "    pat.dob,\n",
        "    DATETIME_DIFF(icu.outtime, icu.intime, DAY) AS icu_length_of_stay,\n",
        "    DATE_DIFF(DATE(icu.intime), DATE(pat.dob), YEAR) AS age,\n",
        "    RANK() OVER (PARTITION BY icu.subject_id ORDER BY icu.intime) AS icustay_id_order\n",
        "  FROM `physionet-data.mimic_demo.icustays` AS icu\n",
        "  INNER JOIN `physionet-data.mimic_demo.patients` AS pat\n",
        "    ON icu.subject_id = pat.subject_id\n",
        "  ORDER BY hadm_id DESC),\n",
        "serv AS (\n",
        "  SELECT\n",
        "    icu.hadm_id,\n",
        "    icu.icustay_id,\n",
        "    se.curr_service,\n",
        "    IF(curr_service like '%SURG' OR curr_service = 'ORTHO', 1, 0) AS surgical,\n",
        "    RANK() OVER (PARTITION BY icu.hadm_id ORDER BY se.transfertime DESC) as rank\n",
        "  FROM `physionet-data.mimic_demo.icustays` AS icu\n",
        "  LEFT JOIN `physionet-data.mimic_demo.services` AS se\n",
        "   ON icu.hadm_id = se.hadm_id\n",
        "  AND se.transfertime < DATETIME_ADD(icu.intime, INTERVAL 12 HOUR)\n",
        "  ORDER BY icustay_id)\n",
        "SELECT\n",
        "  co.subject_id,\n",
        "  co.hadm_id,\n",
        "  co.icustay_id,\n",
        "  co.icu_length_of_stay,\n",
        "  co.age,\n",
        "  IF(co.icu_length_of_stay < 2, 1, 0) AS short_stay,\n",
        "  IF(co.icustay_id_order = 1, 0, 1) AS first_stay,\n",
        "  IF(serv.surgical = 1, 1, 0) AS surgical\n",
        "FROM co\n",
        "LEFT JOIN serv USING (icustay_id, hadm_id)\n",
        "WHERE\n",
        "  serv.rank = 1 AND age < 100\n",
        "ORDER BY subject_id, icustay_id_order\n",
        "''')\n",
        "\n",
        "print 'Number of rows in dataframe: %d' % len(df)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d4nxxe69VDqH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is a long query, but is pretty simple if we take a closer look. It consists of 3 steps as well:\n",
        "\n",
        "1.   We are trying to know how many ICU admissions each patient has by joining `icustays` and `patients`. Note that since each patient may be admitted multiple times, we usually filter out follow-up ICU stays, and only keep the first one to minimize unwanted data correlation. This is achieved by partitioning over `subject_id`, and ordering by admission time, then choose only the first one with `RANK` function, the result is saved to a temporary table `co`;\n",
        "2.   Next we are looking for first services in ICU stays for patients, and also adding a label to indicate whether last services before ICU admission were surgical, similarly the result is saved to `serv`;\n",
        "3.   Lastly, we are ready to save this surgical exclusion label to a cohort generation table by joining the two tables, `co` and `serv`. For the convenience of later analysis, we rename some columns, and filter out patients more than 100 years old."
      ]
    },
    {
      "metadata": {
        "id": "t7IRBm4EBau8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### ML Model Training\n",
        "\n",
        "Next we will show an example of using [Tensorflow](https://www.tensorflow.org/) ([getting started doc](https://www.tensorflow.org/get_started/)) to build a simple predictor, where we use the patient's age and whether it is the first ICU stay to predict whether the ICU stay will be a short one. With only 127 data points in total, we don't expect to actually build an accurate or useful predictor, but it should serve the purpose of showing how a model can be trained and used using Tensorflow within Colab.\n",
        "\n",
        "First, let us split the 127 data points into a training set with 100 records and a testing set with 27, and examine the distribution of the split sets to make sure that the distribution is similar."
      ]
    },
    {
      "metadata": {
        "id": "QPP17fQL3LDa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data = df[['age', 'first_stay', 'short_stay']]\n",
        "data.reindex(np.random.permutation(data.index))\n",
        "training_df=data.head(100)\n",
        "validation_df=data.tail(27)\n",
        "\n",
        "print \"Training data summary:\"\n",
        "display(training_df.describe())\n",
        "\n",
        "print \"Validation data summary:\"\n",
        "display(validation_df.describe())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v6uU-mRh3PAS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And let's quickly check the label distribution for the features."
      ]
    },
    {
      "metadata": {
        "id": "KkfdyF7K3Q3z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "display(training_df.groupby(['short_stay', 'first_stay']).count())\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "shorts = training_df[training_df.short_stay==1].age \n",
        "longs = training_df[training_df.short_stay==0].age \n",
        "colors = ['b', 'g']\n",
        "ax.hist([shorts, longs], bins=10, color=colors, label=['short_stay=1', 'short_stay=0'])\n",
        "ax.set_xlabel('Age')\n",
        "ax.set_ylabel('Number of Patients')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MrpVGVYx3S7_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's first build a linear regression model to predict the numeric value of \"short_stay\" based on age and first_stay features. You can tune the parameters on the right-hand side and observe differences in the evaluation result."
      ]
    },
    {
      "metadata": {
        "id": "R-7VB9pc3Vll",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Linear Regression Parameters {display-mode:\"both\"}\n",
        "BATCH_SIZE = 5 # @param\n",
        "NUM_EPOCHS = 100 # @param\n",
        "\n",
        "first_stay = tf.feature_column.numeric_column('first_stay')\n",
        "age = tf.feature_column.numeric_column('age')\n",
        "\n",
        "# Build linear regressor\n",
        "linear_regressor = tf.estimator.LinearRegressor(feature_columns=[first_stay, age])\n",
        "\n",
        "# Train the Model.\n",
        "model = linear_regressor.train(\n",
        "    input_fn=tf.estimator.inputs.pandas_input_fn(\n",
        "        x=training_df,\n",
        "        y=training_df['short_stay'],\n",
        "        num_epochs=100,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True),\n",
        "    steps=100)\n",
        "\n",
        "# Evaluate the model.\n",
        "eval_result = linear_regressor.evaluate(\n",
        "    input_fn=tf.estimator.inputs.pandas_input_fn(\n",
        "        x=validation_df,\n",
        "        y=validation_df['short_stay'],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False))\n",
        "\n",
        "display(eval_result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8SsUXasz3YUS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Remember that the label `short_stay` is actually categorical, with the value 1 for an ICU stay of 1 day or less and value 0 for stays of length 2 days or more. So a classification model better fits this task. Here we try a deep neural networks model using the `DNNClassifier` estimator. Notice the little changes from the regression code above."
      ]
    },
    {
      "metadata": {
        "id": "Ie7BzB_f3aFk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#@title ML Training example {display-mode:\"both\"}\n",
        "BATCH_SIZE = 5        # @param\n",
        "NUM_EPOCHS = 100       # @param\n",
        "HIDDEN_UNITS=[10, 10] # @param\n",
        "\n",
        "# Build linear regressor\n",
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=[first_stay, age],\n",
        "    hidden_units=HIDDEN_UNITS)\n",
        "\n",
        "# Train the Model.\n",
        "model = classifier.train(\n",
        "    input_fn=tf.estimator.inputs.pandas_input_fn(\n",
        "        x=training_df,\n",
        "        y=training_df['short_stay'],\n",
        "        num_epochs=100,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True),\n",
        "    steps=100)\n",
        "\n",
        "# Evaluate the model.\n",
        "eval_result = classifier.evaluate(\n",
        "    input_fn=tf.estimator.inputs.pandas_input_fn(\n",
        "        x=validation_df,\n",
        "        y=validation_df['short_stay'],\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False))\n",
        "\n",
        "display(eval_result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dtoC3w63BcIV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Congratulations! Now you have finished this datathon tutorial, and ready to explore the real data by querying Google BigQuery. To do so, simply use `mimiciii_clinical` as the dataset name. For example, the table `mimic_demo.icustays` becomes `mimiciii_clinical.icustays` when you need the actual MIMIC data. One thing to note though, is that it is highly recommended to aggregate data aggressively wherever possible, because large dataframes may cause the performance of colab to drop drastically or even out of memory errors.\n",
        "\n",
        "Now, let's do the substitution and, and start the real datathon exploration."
      ]
    },
    {
      "metadata": {
        "id": "akiFriVABdPk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Enjoy!"
      ]
    }
  ]
}